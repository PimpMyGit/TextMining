{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\tommaso\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "C:\\Users\\tommaso\\AppData\\Roaming\\Python\\Python39\\site-packages\\statsmodels\\compat\\pandas.py:65: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  from pandas import Int64Index as NumericIndex\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\tommaso\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34mDone → COMODO.COMODO.CONSTANTS in register_consts() → Comodo's costants correctly configured\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "\"\"\" Import zone \"\"\"\n",
    "\n",
    "import math\n",
    "import html\n",
    "import datetime\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize, wordpunct_tokenize, sent_tokenize\n",
    "from nltk.stem import WordNetLemmatizer; nltk.download('wordnet')\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "\n",
    "from sklearn.metrics import silhouette_score\n",
    "\n",
    "import spacy; spacy_nlp = spacy.load(\"en_core_web_sm\", disable=['ner', 'entity_linker', 'entity_ruler', 'textcat', 'textcat_multilabel', 'morphologizer', 'senter', 'sentencizer', 'transformer'])\n",
    "\n",
    "# !pip install git+https://github.com/PimpMyGit/Comodo.git\n",
    "from comodo.comodo.comodo import * # if fail try from comodo.comodo import *\n",
    "\n",
    "import support\n",
    "register_consts(support.comodo_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DF Train shape:   (161297, 6)     NaN: {'nan_percentage': 0.005573569254232875, 'condition': 899}\n",
      "DF Test shape:    (53766, 6)      NaN: {'nan_percentage': 0.0054867388312316336, 'condition': 295}\n",
      "Drop NaN then.. \n",
      "\n",
      "Reparir: delete records with \"users found this comment helpful *\" and add an upper \"F\" to not-capitalized condition \n",
      "\n",
      "DF Train shape:   (159498, 7)     NaN: {}\n",
      "DF Test shape:    (53200, 7)      NaN: {}\n"
     ]
    }
   ],
   "source": [
    "\"\"\" Lettura DataFrame e piccole modifiche di formato \"\"\"\n",
    "\n",
    "trdf = DF.rcsv('original/drugsComTrain_raw', sep='\\t')\n",
    "del trdf['Unnamed: 0']\n",
    "trdf.columns = ['drug', 'condition', 'review', 'rating', 'date', 'useful']\n",
    "trdf['date'] = trdf['date'].apply(lambda d: UTILS.to_datetime(d, '%B %d, %Y', as_str=True))\n",
    "trdf = trdf.sort_values('date')\n",
    "\n",
    "tsdf = DF.rcsv('original/drugsComTest_raw', sep='\\t')\n",
    "del tsdf['Unnamed: 0']\n",
    "tsdf.columns = ['drug', 'condition', 'review', 'rating', 'date', 'useful']\n",
    "tsdf['date'] = tsdf['date'].apply(lambda d: UTILS.to_datetime(d, '%B %d, %Y', as_str=True))\n",
    "\n",
    "print('DF Train shape:  ', trdf.shape, '    NaN:', DF.has_nan(trdf))\n",
    "print('DF Test shape:   ', tsdf.shape, '     NaN:', DF.has_nan(tsdf))\n",
    "\n",
    "print('Drop NaN then..', '\\n')\n",
    "trdf = trdf.dropna()\n",
    "tsdf = tsdf.dropna()\n",
    "\n",
    "print('Reparir: delete records with \"users found this comment helpful *\" and add an upper \"F\" to not-capitalized condition', '\\n')\n",
    "trdf = DF.add_order_column(trdf)\n",
    "tsdf = DF.add_order_column(tsdf)\n",
    "trdf = DF.find(trdf, {'order': ['!']+DF.find(trdf, {'condition':['re','users found*']})['order'].to_list()}).copy()\n",
    "tsdf = DF.find(tsdf, {'order': ['!']+DF.find(tsdf, {'condition':['re','users found*']})['order'].to_list()}).copy()\n",
    "trdf['condition'] = trdf['condition'].apply(lambda c: 'F'+c if c[0].islower() else c)\n",
    "tsdf['condition'] = tsdf['condition'].apply(lambda c: 'F'+c if c[0].islower() else c)\n",
    "\n",
    "print('DF Train shape:  ', trdf.shape, '    NaN:', DF.has_nan(trdf))\n",
    "print('DF Test shape:   ', tsdf.shape, '     NaN:', DF.has_nan(tsdf))\n",
    "trdf = DF.add_order_column(trdf)\n",
    "tsdf = DF.add_order_column(tsdf)\n",
    "\n",
    "# DF.wcsv(trdf, 'start/train_df.csv', sep='\\t')\n",
    "# DF.wcsv(tsdf, 'start/test_df.csv', sep='\\t')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"border: 1px solid orange; background-color: orange\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DF Train shape:   (159498, 7)     NaN: {}\n",
      "DF Test shape:    (53200, 7)      NaN: {}\n"
     ]
    }
   ],
   "source": [
    "\"\"\" Lettura DataFrame iniziali \"\"\"\n",
    "\n",
    "trdf = DF.set_datetime_index(DF.rcsv('start/train_df.csv', sep='\\t'), 'date')\n",
    "tsdf = DF.set_datetime_index(DF.rcsv('start/test_df.csv', sep='\\t'), 'date')\n",
    "\n",
    "print('DF Train shape:  ', trdf.shape, '    NaN:', DF.has_nan(trdf))\n",
    "print('DF Test shape:   ', tsdf.shape, '     NaN:', DF.has_nan(tsdf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[drug]       - Total drugs:       3412\n",
      "[condition]  - Total conditions:  811\n",
      "[rating]     - Ratings distr.:    {'mean': 6.99714729965266, 'q25': 5.0, 'q50': 8.0, 'q75': 10.0}\n",
      "[date]       - Date distr.:       {2016: 34697, 2017: 28013, 2008: 5011, 2009: 11464, 2010: 8097, 2011: 11308, 2012: 9717, 2013: 12195, 2014: 11969, 2015: 27027}\n",
      "[useful]     - Useful distr.:     {'mean': 28.19233470012163, 'q25': 6.0, 'q50': 16.0, 'q75': 37.0, 'max': 1291.0}\n"
     ]
    }
   ],
   "source": [
    "\"\"\" Descrizione variabili \"\"\"\n",
    "\n",
    "print('[drug]       - Total drugs:      ', len(set(trdf['drug'])))\n",
    "print('[condition]  - Total conditions: ', len(set(trdf['condition'])))\n",
    "print('[rating]     - Ratings distr.:   ', DICT.filter_key(DF.describe(trdf, 'rating', print_res=False, print_plot=False), lambda k: k in ['mean', 'q25', 'q50', 'q75']))\n",
    "print('[date]       - Date distr.:      ', {year: trdf[trdf.index.year == year].shape[0] for year in list(set(trdf.index.year))})\n",
    "print('[useful]     - Useful distr.:    ', DICT.filter_key(DF.describe(trdf, 'useful', print_res=False, print_plot=False), lambda k: k in ['mean', 'q25', 'q50', 'q75', 'max']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Applying LOWER ..\n",
      "Applying NO_QUOTE ..\n",
      "Applying DECODE_HTML ..\n",
      "Applying NO_URL ..\n",
      "Applying NO_EMOJI ..\n",
      "Applying NO_ESCAPE ..\n",
      "Applying NO_PUNCTUATION ..\n",
      "Applying NO_NUMBERS ..\n",
      "Applying NO_ELLIPSIS ..\n"
     ]
    }
   ],
   "source": [
    "\"\"\" Text preporcessing \"\"\"\n",
    "\n",
    "for name,function in OBJECTS._PREPROCESS_STEPS.items():\n",
    "    print('Applying', name, '..')\n",
    "    trdf['review'] = trdf['review'].apply(lambda s: function(s))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"border: 1px solid orange; background-color: orange\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Sentence and word tokenization + POS Tagging \"\"\"\n",
    "\n",
    "# all_sentences = [sent_tokenize(review) for review in trdf['review']]\n",
    "# all_words = [[word_tokenize(sentence) if len(sentence)>0 else '' for sentence in sentences] for sentences in all_sentences]\n",
    "# all_pos_tag = [[nltk.pos_tag(words) for words in sentence] for sentence in all_words]\n",
    "\n",
    "# _ = UTILS.pkl_save('pkl/all_sentences', all_sentences)\n",
    "# _ = UTILS.pkl_save('pkl/all_words', all_words)\n",
    "# _ = UTILS.pkl_save('pkl/all_pos_tag', all_pos_tag)\n",
    "\n",
    "all_sentences = UTILS.pkl_load('pkl/all_sentences')\n",
    "all_words = UTILS.pkl_load('pkl/all_words')\n",
    "all_pos_tag = UTILS.pkl_load('pkl/all_pos_tag')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Filtering by POS Tag (N+J+V+R) -Stopwords \"\"\"\n",
    "\n",
    "lemmatizer = spacy_nlp.get_pipe(\"lemmatizer\")\n",
    "all_sentences_NJVR_lemmatized = []\n",
    "\n",
    "for iR,review in enumerate(all_pos_tag):\n",
    "    entry_review = []\n",
    "    for iS,sentence in enumerate(review):\n",
    "        entry_sentence = []\n",
    "        \n",
    "        # FILTER NJVR -STOPWORDS\n",
    "        [entry_sentence.append(spacy_nlp(word[0])[0].lemma_) for word in sentence if word[1] in OBJECTS._POS_TAG['TO_KEEP'] and word[1] not in OBJECTS._STOPWORDS]\n",
    "        \n",
    "        entry_review.append(entry_sentence)\n",
    "    all_sentences_NJVR_lemmatized.append(entry_review)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>drug</th>\n",
       "      <th>condition</th>\n",
       "      <th>review</th>\n",
       "      <th>rating</th>\n",
       "      <th>date</th>\n",
       "      <th>useful</th>\n",
       "      <th>order</th>\n",
       "      <th>prep_review</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2008-02-24</th>\n",
       "      <td>Chlorpheniramine / pseudoephedrine</td>\n",
       "      <td>Allergic Rhinitis</td>\n",
       "      <td>i when to a medical clinic with flu like sympt...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2008-02-24</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>medical clinic flu symptom Dr. duty prescribe ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2008-02-24</th>\n",
       "      <td>Oxybutynin</td>\n",
       "      <td>Not Listed / Othe</td>\n",
       "      <td>improved my problem dramatically. i never expe...</td>\n",
       "      <td>7.0</td>\n",
       "      <td>2008-02-24</td>\n",
       "      <td>22</td>\n",
       "      <td>1</td>\n",
       "      <td>improve problem dramatically|never experience ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2008-02-24</th>\n",
       "      <td>Xenical</td>\n",
       "      <td>Obesity</td>\n",
       "      <td>xenical really helped me but some of the bowel...</td>\n",
       "      <td>7.0</td>\n",
       "      <td>2008-02-24</td>\n",
       "      <td>50</td>\n",
       "      <td>2</td>\n",
       "      <td>xenical really help bowel problem have make ma...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          drug          condition  \\\n",
       "date                                                                \n",
       "2008-02-24  Chlorpheniramine / pseudoephedrine  Allergic Rhinitis   \n",
       "2008-02-24                          Oxybutynin  Not Listed / Othe   \n",
       "2008-02-24                             Xenical            Obesity   \n",
       "\n",
       "                                                       review  rating  \\\n",
       "date                                                                    \n",
       "2008-02-24  i when to a medical clinic with flu like sympt...     1.0   \n",
       "2008-02-24  improved my problem dramatically. i never expe...     7.0   \n",
       "2008-02-24  xenical really helped me but some of the bowel...     7.0   \n",
       "\n",
       "                  date  useful  order  \\\n",
       "date                                    \n",
       "2008-02-24  2008-02-24       0      0   \n",
       "2008-02-24  2008-02-24      22      1   \n",
       "2008-02-24  2008-02-24      50      2   \n",
       "\n",
       "                                                  prep_review  \n",
       "date                                                           \n",
       "2008-02-24  medical clinic flu symptom Dr. duty prescribe ...  \n",
       "2008-02-24  improve problem dramatically|never experience ...  \n",
       "2008-02-24  xenical really help bowel problem have make ma...  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\" Back to Dataset \"\"\"\n",
    "\n",
    "trdf['clean_review'] = trdf.apply(lambda r: '|'.join([' '.join(sentence) for sentence in all_sentences_NJVR_lemmatized[r['order']]]), axis = 1)\n",
    "trdf.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" SPACY Lemmatization \"\"\"\n",
    "\n",
    "trdf['prep_review'] = trdf['clean_review'].apply(lambda review: '|'.join([' '.join([spacy_nlp(word)[0].lemma_ for word in sentence.split()]) for sentence in review.split('|')]))\n",
    "trdf.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"border: 1px solid orange; background-color: orange\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>drug</th>\n",
       "      <th>condition</th>\n",
       "      <th>review</th>\n",
       "      <th>rating</th>\n",
       "      <th>date</th>\n",
       "      <th>useful</th>\n",
       "      <th>order</th>\n",
       "      <th>clean_review</th>\n",
       "      <th>prep_review</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2008-02-24</th>\n",
       "      <td>Chlorpheniramine / pseudoephedrine</td>\n",
       "      <td>Allergic Rhinitis</td>\n",
       "      <td>i when to a medical clinic with flu like sympt...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2008-02-24</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>i medical clinic flu symptoms dr. duty prescri...</td>\n",
       "      <td>I medical clinic flu symptom dr duty prescribe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2008-02-24</th>\n",
       "      <td>Oxybutynin</td>\n",
       "      <td>Not Listed / Othe</td>\n",
       "      <td>improved my problem dramatically. i never expe...</td>\n",
       "      <td>7.0</td>\n",
       "      <td>2008-02-24</td>\n",
       "      <td>22</td>\n",
       "      <td>1</td>\n",
       "      <td>improved problem dramatically|i never experien...</td>\n",
       "      <td>improve problem dramatically|I never experienc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2008-02-24</th>\n",
       "      <td>Xenical</td>\n",
       "      <td>Obesity</td>\n",
       "      <td>xenical really helped me but some of the bowel...</td>\n",
       "      <td>7.0</td>\n",
       "      <td>2008-02-24</td>\n",
       "      <td>50</td>\n",
       "      <td>2</td>\n",
       "      <td>xenical really helped bowel problems i had mad...</td>\n",
       "      <td>xenical really help bowel problem I have make ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          drug          condition  \\\n",
       "date                                                                \n",
       "2008-02-24  Chlorpheniramine / pseudoephedrine  Allergic Rhinitis   \n",
       "2008-02-24                          Oxybutynin  Not Listed / Othe   \n",
       "2008-02-24                             Xenical            Obesity   \n",
       "\n",
       "                                                       review  rating  \\\n",
       "date                                                                    \n",
       "2008-02-24  i when to a medical clinic with flu like sympt...     1.0   \n",
       "2008-02-24  improved my problem dramatically. i never expe...     7.0   \n",
       "2008-02-24  xenical really helped me but some of the bowel...     7.0   \n",
       "\n",
       "                  date  useful  order  \\\n",
       "date                                    \n",
       "2008-02-24  2008-02-24       0      0   \n",
       "2008-02-24  2008-02-24      22      1   \n",
       "2008-02-24  2008-02-24      50      2   \n",
       "\n",
       "                                                 clean_review  \\\n",
       "date                                                            \n",
       "2008-02-24  i medical clinic flu symptoms dr. duty prescri...   \n",
       "2008-02-24  improved problem dramatically|i never experien...   \n",
       "2008-02-24  xenical really helped bowel problems i had mad...   \n",
       "\n",
       "                                                  prep_review  \n",
       "date                                                           \n",
       "2008-02-24  I medical clinic flu symptom dr duty prescribe...  \n",
       "2008-02-24  improve problem dramatically|I never experienc...  \n",
       "2008-02-24  xenical really help bowel problem I have make ...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\" Starts with preprocessed datafarame \"\"\"\n",
    "\n",
    "step = 'prep'\n",
    "trdf = DF.set_datetime_index(DF.rcsv(step+'/train_df.csv', sep='\\t'), 'date')\n",
    "trdf.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocab length: 37732\n",
      "Original vocab length: 61580\n"
     ]
    }
   ],
   "source": [
    "\"\"\" Vocabulary \"\"\"\n",
    "\n",
    "all_vocab = []\n",
    "_ = [[[all_vocab.append(w) for w in s.split()] if type(s) is str else '' for s in r.split('|')] if type(r) is str else '' for r in trdf['prep_review'].to_list()]\n",
    "vocab = set(all_vocab)\n",
    "vocab_occurrences = LIST.occurrences(all_vocab)\n",
    "print('Vocab length:', len(vocab))\n",
    "\n",
    "all_vocab_original = []\n",
    "_ = [[all_vocab_original.append(w) if type(w) is str else '' for w in r.split(' ')] if type(r) is str else '' for r in trdf['review'].to_list()]\n",
    "vocab_original = set(all_vocab_original)\n",
    "vocab_original_ccurrences = LIST.occurrences(all_vocab_original)\n",
    "print('Original vocab length:', len(vocab_original))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reviews containg dot \".\" : 9000\n",
      "Drop all them → keep at least 91.62873515655369 % of total\n",
      "Now size: (148256, 9)\n"
     ]
    }
   ],
   "source": [
    "\"\"\" Vocabulary Analysis\"\"\"\n",
    "\n",
    "print('Reviews containg dot \".\" :', sum(list(DICT.dfilter(vocab_occurrences, lambda x: '.' in x).values())))\n",
    "print('Drop all them → keep at least', str(100*(trdf.shape[0]-9000)/DF.rcsv('start/train_df.csv', sep='\\t').shape[0]), '% of total')\n",
    "trdf = DF.find_lambda(trdf, lambda r: '.' not in r['prep_review'] if type(r['prep_review'])is str else False)\n",
    "trdf['prep_review'] = trdf['prep_review'].apply(lambda r: r.lower())\n",
    "print('Now size:', trdf.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Write DF ready for Analysis \"\"\"\n",
    "\n",
    "del trdf['clean_review']    # Non serve più, non è la definitiva\n",
    "del trdf['order']           # Non congruente dopo clean finale\n",
    "\n",
    "trdf.rename(columns={'review': 'original_review', 'prep_review': 'review'}, inplace=True)\n",
    "\n",
    "trdf['review'] = trdf['review'].apply(lambda r: r.lower())\n",
    "# Forme negative -> replace 'not# ' per tenerle | 'not' per convertire tutto in not | '' per eliminarle\n",
    "trdf['review'] = trdf['review'].apply(lambda r: '|'.join([' '.join(LIST.lfilter([w if w not in OBJECTS._NEG_STOPWORDS else 'not#' for i,w in enumerate(s.split()) if w not in OBJECTS._STOPWORDS or (w in OBJECTS._STOPWORDS and w in OBJECTS._NEG_STOPWORDS)], lambda w:w!='')).replace('# ', '_') for s in r.split('|')]))\n",
    "\n",
    "trdf['review_words'] = trdf['review'].apply(lambda r: ' '.join([' '.join(s.split()) for s in r.split('|')]))\n",
    "\n",
    "trdf = trdf.drop_duplicates(subset='review_words')\n",
    "trdf = DF.add_order_column(trdf)\n",
    "\n",
    "trdf = trdf[['drug', 'condition', 'original_review', 'review', 'review_words', 'rating', 'useful', 'date', 'order']]\n",
    "\n",
    "DF.wcsv(trdf, 'analysis/train_df.csv', sep='\\t')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"border: 1px solid orange; background-color: orange\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>drug</th>\n",
       "      <th>condition</th>\n",
       "      <th>original_review</th>\n",
       "      <th>review</th>\n",
       "      <th>review_words</th>\n",
       "      <th>rating</th>\n",
       "      <th>useful</th>\n",
       "      <th>date</th>\n",
       "      <th>order</th>\n",
       "      <th>review_words_luhn</th>\n",
       "      <th>all_bg</th>\n",
       "      <th>jn_constr</th>\n",
       "      <th>vj_constr</th>\n",
       "      <th>rj_constr</th>\n",
       "      <th>rv_constr</th>\n",
       "      <th>vr_constr</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2008-02-24</th>\n",
       "      <td>Chlorpheniramine / pseudoephedrine</td>\n",
       "      <td>Allergic Rhinitis</td>\n",
       "      <td>i when to a medical clinic with flu like sympt...</td>\n",
       "      <td>medical clinic flu symptom dr duty prescribe d...</td>\n",
       "      <td>medical clinic flu symptom dr duty prescribe d...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2008-02-24</td>\n",
       "      <td>0</td>\n",
       "      <td>medical clinic flu symptom dr duty know seriou...</td>\n",
       "      <td>symptom dr|flu symptom</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>symptom dr</td>\n",
       "      <td>flu symptom</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2008-02-24</th>\n",
       "      <td>Oxybutynin</td>\n",
       "      <td>Not Listed / Othe</td>\n",
       "      <td>improved my problem dramatically. i never expe...</td>\n",
       "      <td>improve problem dramatically|never experience ...</td>\n",
       "      <td>improve problem dramatically never experience ...</td>\n",
       "      <td>7.0</td>\n",
       "      <td>22</td>\n",
       "      <td>2008-02-24</td>\n",
       "      <td>1</td>\n",
       "      <td>improve dramatically major</td>\n",
       "      <td>experience major|never experience</td>\n",
       "      <td>NaN</td>\n",
       "      <td>experience major</td>\n",
       "      <td>NaN</td>\n",
       "      <td>never experience</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2008-02-24</th>\n",
       "      <td>Xenical</td>\n",
       "      <td>Obesity</td>\n",
       "      <td>xenical really helped me but some of the bowel...</td>\n",
       "      <td>xenical really help bowel problem make margina...</td>\n",
       "      <td>xenical really help bowel problem make margina...</td>\n",
       "      <td>7.0</td>\n",
       "      <td>50</td>\n",
       "      <td>2008-02-24</td>\n",
       "      <td>2</td>\n",
       "      <td>xenical bowel marginal hit</td>\n",
       "      <td>hit side</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>hit side</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2008-02-24</th>\n",
       "      <td>Macrobid</td>\n",
       "      <td>Bladder Infection</td>\n",
       "      <td>excellent for prevention of bladder infection ...</td>\n",
       "      <td>excellent prevention bladder infection cns com...</td>\n",
       "      <td>excellent prevention bladder infection cns com...</td>\n",
       "      <td>8.0</td>\n",
       "      <td>52</td>\n",
       "      <td>2008-02-24</td>\n",
       "      <td>3</td>\n",
       "      <td>excellent prevention bladder infection cns com...</td>\n",
       "      <td>bladder infection</td>\n",
       "      <td>NaN</td>\n",
       "      <td>bladder infection</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2008-02-25</th>\n",
       "      <td>Fentanyl</td>\n",
       "      <td>Pain</td>\n",
       "      <td>i don t think i could make it without the patc...</td>\n",
       "      <td>not_think make patch|pain back point live|fent...</td>\n",
       "      <td>not_think make patch pain back point live fent...</td>\n",
       "      <td>10.0</td>\n",
       "      <td>22</td>\n",
       "      <td>2008-02-25</td>\n",
       "      <td>4</td>\n",
       "      <td>not_think patch point live patch way</td>\n",
       "      <td>make patch|much pain|not_think make|take much|...</td>\n",
       "      <td>make patch|much pain</td>\n",
       "      <td>not_think make|take much</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>point live</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2008-02-25</th>\n",
       "      <td>Humira</td>\n",
       "      <td>Crohn's Disease, Maintenance</td>\n",
       "      <td>my name is serena. i have had chron s disease ...</td>\n",
       "      <td>name serena|chron disease year|surgery year ag...</td>\n",
       "      <td>name serena chron disease year surgery year ag...</td>\n",
       "      <td>10.0</td>\n",
       "      <td>111</td>\n",
       "      <td>2008-02-25</td>\n",
       "      <td>5</td>\n",
       "      <td>name disease surgery flare surgery gi humira m...</td>\n",
       "      <td>flare week|normal life|get lead|put humira|gi ...</td>\n",
       "      <td>flare week|normal life</td>\n",
       "      <td>NaN</td>\n",
       "      <td>get lead</td>\n",
       "      <td>put humira</td>\n",
       "      <td>gi put|humira miracle</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2008-02-25</th>\n",
       "      <td>Buprenorphine</td>\n",
       "      <td>Opiate Dependence</td>\n",
       "      <td>it s works great if your really ready to stop ...</td>\n",
       "      <td>work great really ready stop take opiate</td>\n",
       "      <td>work great really ready stop take opiate</td>\n",
       "      <td>8.0</td>\n",
       "      <td>78</td>\n",
       "      <td>2008-02-25</td>\n",
       "      <td>6</td>\n",
       "      <td>ready opiate</td>\n",
       "      <td>really ready|stop take|ready stop</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>really ready|stop take</td>\n",
       "      <td>ready stop</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2008-02-25</th>\n",
       "      <td>Methylphenidate</td>\n",
       "      <td>ADHD</td>\n",
       "      <td>my son was taking the mg for yrs when all of a...</td>\n",
       "      <td>son take mg yrs sudden start get severely depr...</td>\n",
       "      <td>son take mg yrs sudden start get severely depr...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>159</td>\n",
       "      <td>2008-02-25</td>\n",
       "      <td>7</td>\n",
       "      <td>son yrs sudden severely depressed thought hurt...</td>\n",
       "      <td>small percentage|seem small|severely depressed...</td>\n",
       "      <td>small percentage</td>\n",
       "      <td>seem small</td>\n",
       "      <td>NaN</td>\n",
       "      <td>severely depressed|immediately take</td>\n",
       "      <td>sudden start|take concerta|read side|read side</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2008-02-25</th>\n",
       "      <td>Balsalazide</td>\n",
       "      <td>Ulcerative Colitis</td>\n",
       "      <td>there is new generic version of colazal now. i...</td>\n",
       "      <td>new generic version colazal|wonder anyone use ...</td>\n",
       "      <td>new generic version colazal wonder anyone use ...</td>\n",
       "      <td>10.0</td>\n",
       "      <td>16</td>\n",
       "      <td>2008-02-25</td>\n",
       "      <td>8</td>\n",
       "      <td>new generic version colazal wonder anyone vs b...</td>\n",
       "      <td>wonder anyone|vs brand|name drug|use find</td>\n",
       "      <td>wonder anyone|vs brand|name drug</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>use find</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2008-02-25</th>\n",
       "      <td>Dolobid</td>\n",
       "      <td>Pain</td>\n",
       "      <td>this medicine is very hard my your stomach and...</td>\n",
       "      <td>medicine hard stomach help pain immediately ex...</td>\n",
       "      <td>medicine hard stomach help pain immediately ex...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>13</td>\n",
       "      <td>2008-02-25</td>\n",
       "      <td>9</td>\n",
       "      <td>hard stomach immediately expensive</td>\n",
       "      <td>stomach help</td>\n",
       "      <td>stomach help</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          drug                     condition  \\\n",
       "date                                                                           \n",
       "2008-02-24  Chlorpheniramine / pseudoephedrine             Allergic Rhinitis   \n",
       "2008-02-24                          Oxybutynin             Not Listed / Othe   \n",
       "2008-02-24                             Xenical                       Obesity   \n",
       "2008-02-24                            Macrobid             Bladder Infection   \n",
       "2008-02-25                            Fentanyl                          Pain   \n",
       "2008-02-25                              Humira  Crohn's Disease, Maintenance   \n",
       "2008-02-25                       Buprenorphine             Opiate Dependence   \n",
       "2008-02-25                     Methylphenidate                          ADHD   \n",
       "2008-02-25                         Balsalazide            Ulcerative Colitis   \n",
       "2008-02-25                             Dolobid                          Pain   \n",
       "\n",
       "                                              original_review  \\\n",
       "date                                                            \n",
       "2008-02-24  i when to a medical clinic with flu like sympt...   \n",
       "2008-02-24  improved my problem dramatically. i never expe...   \n",
       "2008-02-24  xenical really helped me but some of the bowel...   \n",
       "2008-02-24  excellent for prevention of bladder infection ...   \n",
       "2008-02-25  i don t think i could make it without the patc...   \n",
       "2008-02-25  my name is serena. i have had chron s disease ...   \n",
       "2008-02-25  it s works great if your really ready to stop ...   \n",
       "2008-02-25  my son was taking the mg for yrs when all of a...   \n",
       "2008-02-25  there is new generic version of colazal now. i...   \n",
       "2008-02-25  this medicine is very hard my your stomach and...   \n",
       "\n",
       "                                                       review  \\\n",
       "date                                                            \n",
       "2008-02-24  medical clinic flu symptom dr duty prescribe d...   \n",
       "2008-02-24  improve problem dramatically|never experience ...   \n",
       "2008-02-24  xenical really help bowel problem make margina...   \n",
       "2008-02-24  excellent prevention bladder infection cns com...   \n",
       "2008-02-25  not_think make patch|pain back point live|fent...   \n",
       "2008-02-25  name serena|chron disease year|surgery year ag...   \n",
       "2008-02-25           work great really ready stop take opiate   \n",
       "2008-02-25  son take mg yrs sudden start get severely depr...   \n",
       "2008-02-25  new generic version colazal|wonder anyone use ...   \n",
       "2008-02-25  medicine hard stomach help pain immediately ex...   \n",
       "\n",
       "                                                 review_words  rating  useful  \\\n",
       "date                                                                            \n",
       "2008-02-24  medical clinic flu symptom dr duty prescribe d...     1.0       0   \n",
       "2008-02-24  improve problem dramatically never experience ...     7.0      22   \n",
       "2008-02-24  xenical really help bowel problem make margina...     7.0      50   \n",
       "2008-02-24  excellent prevention bladder infection cns com...     8.0      52   \n",
       "2008-02-25  not_think make patch pain back point live fent...    10.0      22   \n",
       "2008-02-25  name serena chron disease year surgery year ag...    10.0     111   \n",
       "2008-02-25           work great really ready stop take opiate     8.0      78   \n",
       "2008-02-25  son take mg yrs sudden start get severely depr...     5.0     159   \n",
       "2008-02-25  new generic version colazal wonder anyone use ...    10.0      16   \n",
       "2008-02-25  medicine hard stomach help pain immediately ex...     1.0      13   \n",
       "\n",
       "                  date  order  \\\n",
       "date                            \n",
       "2008-02-24  2008-02-24      0   \n",
       "2008-02-24  2008-02-24      1   \n",
       "2008-02-24  2008-02-24      2   \n",
       "2008-02-24  2008-02-24      3   \n",
       "2008-02-25  2008-02-25      4   \n",
       "2008-02-25  2008-02-25      5   \n",
       "2008-02-25  2008-02-25      6   \n",
       "2008-02-25  2008-02-25      7   \n",
       "2008-02-25  2008-02-25      8   \n",
       "2008-02-25  2008-02-25      9   \n",
       "\n",
       "                                            review_words_luhn  \\\n",
       "date                                                            \n",
       "2008-02-24  medical clinic flu symptom dr duty know seriou...   \n",
       "2008-02-24                         improve dramatically major   \n",
       "2008-02-24                         xenical bowel marginal hit   \n",
       "2008-02-24  excellent prevention bladder infection cns com...   \n",
       "2008-02-25               not_think patch point live patch way   \n",
       "2008-02-25  name disease surgery flare surgery gi humira m...   \n",
       "2008-02-25                                       ready opiate   \n",
       "2008-02-25  son yrs sudden severely depressed thought hurt...   \n",
       "2008-02-25  new generic version colazal wonder anyone vs b...   \n",
       "2008-02-25                 hard stomach immediately expensive   \n",
       "\n",
       "                                                       all_bg  \\\n",
       "date                                                            \n",
       "2008-02-24                             symptom dr|flu symptom   \n",
       "2008-02-24                  experience major|never experience   \n",
       "2008-02-24                                           hit side   \n",
       "2008-02-24                                  bladder infection   \n",
       "2008-02-25  make patch|much pain|not_think make|take much|...   \n",
       "2008-02-25  flare week|normal life|get lead|put humira|gi ...   \n",
       "2008-02-25                  really ready|stop take|ready stop   \n",
       "2008-02-25  small percentage|seem small|severely depressed...   \n",
       "2008-02-25          wonder anyone|vs brand|name drug|use find   \n",
       "2008-02-25                                       stomach help   \n",
       "\n",
       "                                   jn_constr                 vj_constr  \\\n",
       "date                                                                     \n",
       "2008-02-24                               NaN                       NaN   \n",
       "2008-02-24                               NaN          experience major   \n",
       "2008-02-24                               NaN                       NaN   \n",
       "2008-02-24                               NaN         bladder infection   \n",
       "2008-02-25              make patch|much pain  not_think make|take much   \n",
       "2008-02-25            flare week|normal life                       NaN   \n",
       "2008-02-25                               NaN                       NaN   \n",
       "2008-02-25                  small percentage                seem small   \n",
       "2008-02-25  wonder anyone|vs brand|name drug                       NaN   \n",
       "2008-02-25                      stomach help                       NaN   \n",
       "\n",
       "           rj_constr                            rv_constr  \\\n",
       "date                                                        \n",
       "2008-02-24       NaN                           symptom dr   \n",
       "2008-02-24       NaN                     never experience   \n",
       "2008-02-24       NaN                                  NaN   \n",
       "2008-02-24       NaN                                  NaN   \n",
       "2008-02-25       NaN                                  NaN   \n",
       "2008-02-25  get lead                           put humira   \n",
       "2008-02-25       NaN               really ready|stop take   \n",
       "2008-02-25       NaN  severely depressed|immediately take   \n",
       "2008-02-25       NaN                                  NaN   \n",
       "2008-02-25       NaN                                  NaN   \n",
       "\n",
       "                                                 vr_constr  \n",
       "date                                                        \n",
       "2008-02-24                                     flu symptom  \n",
       "2008-02-24                                             NaN  \n",
       "2008-02-24                                        hit side  \n",
       "2008-02-24                                             NaN  \n",
       "2008-02-25                                      point live  \n",
       "2008-02-25                           gi put|humira miracle  \n",
       "2008-02-25                                      ready stop  \n",
       "2008-02-25  sudden start|take concerta|read side|read side  \n",
       "2008-02-25                                        use find  \n",
       "2008-02-25                                             NaN  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\" Read DF for analysis \"\"\"\n",
    "\n",
    "trdf = DF.set_datetime_index(DF.rcsv('analysis/train_df.csv', sep='\\t'), 'date')\n",
    "trdf.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Now size: 102012\n",
      "Kept conditions: 225\n"
     ]
    }
   ],
   "source": [
    "\"\"\" Remove condtions under 35 reviews \"\"\"\n",
    "\n",
    "keep_condition = list(DICT.dfilter(LIST.occurrences(trdf['condition']), by='value', lambda_fun=lambda v: v>=35).keys())\n",
    "trdf = DF.find(trdf, {'condition': keep_condition})\n",
    "\n",
    "print('Now size:', trdf.shape[0])\n",
    "print('Kept conditions:', len(keep_condition))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Raggruppo per condizione \"\"\"\n",
    "\n",
    "# Insomnia\n",
    "# Back Pain\n",
    "# Anxiety\n",
    "# Depression\n",
    "# ADHD\n",
    "# Obesity\n",
    "# Birth Control\n",
    "# Erectile Dysfunction\n",
    "# Vaginal Yeast Infection\n",
    "\n",
    "target_condition = 'Vaginal Yeast Infection'\n",
    "\n",
    "gr_condition = trdf.groupby('condition')\n",
    "grc = gr_condition.get_group(target_condition)\n",
    "\n",
    "DO_ENTIRE_DATAFRAME = False\n",
    "\n",
    "grc = trdf.copy() if DO_ENTIRE_DATAFRAME else grc.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Describe variable: values\n",
      "\n",
      "• n obs :   4145\n",
      "• mean :   1.13729794933655\n",
      "• variance :   2.068999453917126\n",
      "• std :   1.3101193684075858\n",
      "• min :   0.0\n",
      "• q25 :   0.0\n",
      "• q50 :   0.0\n",
      "• q75 :   1.0\n",
      "• max :   7.0\n",
      "• range :   7.0\n",
      "• skewness :   1.3721939602229216\n",
      "• kurtosis :   1.4507112878906554\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tommaso\\AppData\\Local\\Temp/ipykernel_19332/2235372927.py:19: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  grc['review_words_luhn'] = grc['review_words'].apply(lambda r: ' '.join([w for w in r.split() if w in keep_vocab]) if type(r) is str else ' ')\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAWAAAAFgCAYAAACFYaNMAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjQuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/Z1A+gAAAACXBIWXMAAAsTAAALEwEAmpwYAAAgO0lEQVR4nO3deXxV9Z3/8dcnO1kggYQtoCAEFEVQWbSKoiionZZuWm2r1NbSTtEftvPo/NTOY2o7j06d/tpOtdOx44Jix7qMYl2KpYrWpS4QEYmAGFYhAklYQyCBJJ/fH/eEuSJLlnvzTcL7+Xjcxz3ne7bPDTzeOfme8z3X3B0REel4KaELEBE5XimARUQCUQCLiASiABYRCUQBLCISiAJYRCSQpAWwmQ02s5fMbIWZLTez2VH7bWZWYWZLo9flcdvcYmarzWyVmU2La780alttZjcf69iXXnqpA3rppZdeneV1WGlHWpAADcA/uPsSM8sD3jaz56Nl/+7uv4hf2cxGAVcBpwIDgRfMbES0+LfAJcAmYLGZPe3uK4504Orq6gR/FBGRxEtaALv7ZmBzNF1jZiuB4qNsMh14xN3rgXVmthqYEC1b7e5rAczskWjdIwawiEhX0CF9wGY2BDgDeCtqusHMlpnZHDMriNqKgY1xm22K2o7UfugxZppZqZmVVlVVJfojiIgkXNID2MxygSeAm9x9N3AXMAwYS+wM+ZeJOI673+3u49x9XFFRUSJ2KSKSVMnsA8bM0omF70PuPg/A3bfGLb8HeDaarQAGx20+KGrjKO0iIl1WMu+CMOA+YKW7/yqufUDcap8H3oumnwauMrNMMxsKlACLgMVAiZkNNbMMYhfqnk5W3SIiHSWZZ8DnAtcAZWa2NGq7FbjazMYSuzVjPfBtAHdfbmaPEbu41gDMcvdGADO7AVgApAJz3H15EusWEekQ1h0fRzlu3DgvLS0NXYaISDM7XKNGwomIBKIAFhEJRAEsIhKIAlhEJBAFsIhIIApgEZFAkjoSrqsZfdsCauoaDs7nZaVRdtu0o2whItJ2CuA4NXUNzJ5ScnD+joXlAasRke5OXRAiIoEogEVEAlEAi4gEogAWEQlEASwiEogCWEQkEAWwiEggCmARkUAUwCIigSiARUQCUQCLiASiABYRCUQBLCISiAJYRCQQBbCISCAKYBGRQBTAIiKBKIBFRAJRAIuIBKIAFhEJRAEsIhKIAlhEJBAFsIhIIApgEZFAFMAiIoEogEVEAlEAi4gEogAWEQlEASwiEogCWEQkEAWwiEggCmARkUAUwCIigSiARUQCUQCLiASiABYRCUQBLCISiAJYRCQQBbCISCAKYBGRQBTAIiKBKIBFRAJRAIuIBKIAFhEJRAEsIhKIAlhEJBAFsIhIIEkLYDMbbGYvmdkKM1tuZrOj9t5m9ryZlUfvBVG7mdmdZrbazJaZ2Zlx+5oRrV9uZjOSVbOISEdK5hlwA/AP7j4KOBuYZWajgJuBhe5eAiyM5gEuA0qi10zgLogFNvAjYCIwAfhRc2iLiHRlSQtgd9/s7kui6RpgJVAMTAfmRqvNBT4XTU8HHvSYN4F8MxsATAOed/ft7r4DeB64NFl1i4h0lA7pAzazIcAZwFtAP3ffHC3aAvSLpouBjXGbbYrajtR+6DFmmlmpmZVWVVUl9gOIiCRB0gPYzHKBJ4Cb3H13/DJ3d8ATcRx3v9vdx7n7uKKiokTsUkQkqZIawGaWTix8H3L3eVHz1qhrgei9MmqvAAbHbT4oajtSu4hIl5bMuyAMuA9Y6e6/ilv0NNB8J8MM4Km49mujuyHOBnZFXRULgKlmVhBdfJsatYmIdGlpSdz3ucA1QJmZLY3abgVuBx4zs28CG4Aro2XzgcuB1cBe4DoAd99uZv8CLI7W+4m7b09i3SIiHSJpAezurwF2hMVTDrO+A7OOsK85wJzEVSciEp5GwomIBKIAFhEJRAEsIhKIAlhEJBAFsIhIIApgEZFAFMAiIoEogEVEAlEAi4gEogAWEQlEASwiEogCWEQkEAWwiEggCmARkUAUwCIigSiARUQCUQCLiASiABYRCUQBLCISiAJYRCQQBbCISCAKYBGRQBTAIiKBKIBFRAJRAIuIBKIAFhEJRAEsIhKIAlhEJBAFsIhIIApgEZFAFMAiIoEogEVEAlEAi4gEogAWEQlEASwiEogCWEQkEAWwiEggCmARkUAUwCIigSiARUQCUQCLiASiABYRCUQBLCISiAJYRCQQBbCISCAKYBGRQBTAIiKBKIBFRAJRAIuIBKIAFhEJRAEsIhKIAlhEJBAFsIhIIApgEZFAkhbAZjbHzCrN7L24ttvMrMLMlkavy+OW3WJmq81slZlNi2u/NGpbbWY3J6teEZGOlswz4AeASw/T/u/uPjZ6zQcws1HAVcCp0Tb/aWapZpYK/Ba4DBgFXB2tKyLS5aUla8fu/oqZDWnh6tOBR9y9HlhnZquBCdGy1e6+FsDMHonWXZHoekVEOlqIPuAbzGxZ1EVRELUVAxvj1tkUtR2p/RPMbKaZlZpZaVVVVTLqFhFJqI4O4LuAYcBYYDPwy0Tt2N3vdvdx7j6uqKgoUbsVEUmapHVBHI67b22eNrN7gGej2QpgcNyqg6I2jtIuItKldegZsJkNiJv9PNB8h8TTwFVmlmlmQ4ESYBGwGCgxs6FmlkHsQt3THVmziEiyJO0M2MweBiYDhWa2CfgRMNnMxgIOrAe+DeDuy83sMWIX1xqAWe7eGO3nBmABkArMcfflyapZRKQjJfMuiKsP03zfUdb/KfDTw7TPB+YnsDQRkU5BI+FERAJRAIuIBKIAFhEJRAEsIhKIAlhEJBAFsIhIIApgEZFAFMAiIoEogEVEAlEAi4gEogAWEQlEASwiEkiLAtjMzm1Jm4iItFxLz4B/08I2ERFpoaM+jtLMzgE+BRSZ2ffjFvUk9nxeERFpo2M9DzgDyI3Wy4tr3w18KVlFiYgcD44awO7+MvCymT3g7hs6qCYRkeNCS78RI9PM7gaGxG/j7hcloygRkeNBSwP4f4DfAfcCjckrR0Tk+NHSAG5w97uSWomIyHGmpbehPWNm3zWzAWbWu/mV1MpERLq5lp4Bz4jefxDX5sBJiS1HROT40aIAdvehyS5EROR406IANrNrD9fu7g8mthwRkeNHS7sgxsdNZwFTgCWAAlhEpI1a2gVxY/y8meUDjySjIBGR40VbH0dZC6hfWESkHVraB/wMsbseIPYQnlOAx5JVlIjI8aClfcC/iJtuADa4+6Yk1CMictxoURdE9FCe94k9Ea0A2J/MokREjgct/UaMK4FFwBXAlcBbZqbHUYqItENLuyB+CIx390oAMysCXgAeT1ZhIiLdXUvvgkhpDt/ItlZsKyIih9HSM+A/m9kC4OFo/svA/OSUJCJyfDjWd8INB/q5+w/M7AvAedGiN4CHkl2ciEh3dqwz4F8DtwC4+zxgHoCZjY6WfSaJtYmIdGvH6sft5+5lhzZGbUOSUpGIyHHiWAGcf5RlPRJYh4jIcedYAVxqZt86tNHMrgfeTk5JIiLHh2P1Ad8EPGlmX+V/A3cckAF8Pol1iYh0e0cNYHffCnzKzC4EToua/+TuLya9MhGRbq6lzwN+CXgpybWIiBxXNJpNRCQQBbCISCAKYBGRQBTAIiKBKIBFRAJRAIuIBKIAFhEJRAEsIhKIAlhEJBAFsIhIIApgEZFAFMAiIoEogEVEAklaAJvZHDOrNLP34tp6m9nzZlYevRdE7WZmd5rZajNbZmZnxm0zI1q/3MxmJKteEZGOlswz4AeASw9puxlY6O4lwMJoHuAyoCR6zQTuglhgAz8CJgITgB81h7aISFeXtAB291eA7Yc0TwfmRtNzgc/FtT/oMW8C+WY2AJgGPO/u2919B/A8nwx1EZEuqaP7gPu5++ZoegvQL5ouBjbGrbcpajtS+yeY2UwzKzWz0qqqqsRWLSKSBMEuwrm7A57A/d3t7uPcfVxRUVGidisikjQdHcBbo64FovfKqL0CGBy33qCo7UjtIiJdXkcH8NNA850MM4Cn4tqvje6GOBvYFXVVLACmmllBdPFtatQmItLltehLOdvCzB4GJgOFZraJ2N0MtwOPmdk3gQ3AldHq84HLgdXAXuA6AHffbmb/AiyO1vuJux96YU9EpEtKWgC7+9VHWDTlMOs6MOsI+5kDzElgaSIinYJGwomIBKIAFhEJRAEsIhKIAlhEJBAFsIhIIApgEZFAFMAiIoEogEVEAlEAi4gEogAWEQlEASwiEogCWEQkEAWwiEggCmARkUAUwCIigSiARUQCUQCLiASiABYRCUQBLCISiAJYRCQQBbCISCAKYBGRQBTAIiKBKIBFRAJJC12AHN3o2xZQU9fwsba8rDTKbpsWqCIRSRQFcCdXU9fA7CklH2u7Y2F5oGpEJJHUBSEiEogCWEQkEAWwiEggCmARkUAUwCIigSiARUQCUQCLiASiABYRCUQBLCISiAJYRCQQBbCISCAKYBGRQBTAIiKBKIBFRAJRAIuIBKIAFhEJRAEsIhKIAlhEJBAFsIhIIApgEZFAFMAiIoEogEVEAlEAi4gEogAWEQlEASwiEogCWEQkEAWwiEggCmARkUCCBLCZrTezMjNbamalUVtvM3vezMqj94Ko3czsTjNbbWbLzOzMEDWLiCRayDPgC919rLuPi+ZvBha6ewmwMJoHuAwoiV4zgbs6vFIRkSToTF0Q04G50fRc4HNx7Q96zJtAvpkNCFCfiEhChQpgB/5iZm+b2cyorZ+7b46mtwD9ouliYGPctpuito8xs5lmVmpmpVVVVcmqW0QkYdICHfc8d68ws77A82b2fvxCd3cz89bs0N3vBu4GGDduXKu2FREJIcgZsLtXRO+VwJPABGBrc9dC9F4ZrV4BDI7bfFDUllC/fuGDRO9SROSoOjyAzSzHzPKap4GpwHvA08CMaLUZwFPR9NPAtdHdEGcDu+K6KhKisqaO+15bB8D8ss246wRaRJIvxBlwP+A1M3sXWAT8yd3/DNwOXGJm5cDF0TzAfGAtsBq4B/huogvqm5fFG7dMAaC8cg+lG3Yk+hAiIp/Q4X3A7r4WGHOY9m3AlMO0OzAr2XXlZsZ+FCP65vLGmm2cVJiT7EOKyHEu1EW4TmvyyL6sra7l7Q91Fnwko29bQE1dw8fa8rLSKLttWqCKRLomBfAhemSkctrAXiyr2Bm6lE6rpq6B2VNKPtZ2x8LyQNWIdF2daSBGp3HGifnoMpyIJJsC+DB6ZqVzQu9sAJqaFMUikhwK4CM4uX8eAIvXbw9ciYh0VwrgIzipMBeAPy79KHAlItJdKYCPICMt9qNZsHwLjeqGEJEkUAAfw/ba/SzdqFvSRCTxFMDHkJZivLCy8tgrioi0kgL4GMYP6c3ClVtDlyEi3ZAC+BimnNKXD7buYeP2vaFLEZFuRgF8DBee3BeAV8r1kHcRSSwF8DGcVJhDcX4PXv2gOnQpItLNKICPwcyYVFLI62uqaWhsCl2OiHQjCuAWOK+kkN11DSyr2BW6FBHpRhTALXDusELMUDeEiCSUArgFCnIyOL24F6/qQpyIJJACuIUmlRTxzsad7K47ELoUEekmFMAtNKmkkMYm540120KXIiLdhAK4hc44oYCcjFR1Q4hIwiiAWygjLYVzhvXh1XJdiBORxFAAt8KkkiI2bNvLhm21oUsRkW5AAdwKk0oKAXQWLCIJoQBuhaHNw5LVDywiCaCvpW8FM+P8EYU8++5mGhqbSEvV76/OZPRtC6ipazg4n5eVRtlt0wJWJHJ0SpBWmlRSRE19A+9u2hm6FDlETV0Ds6eUHHzFh7FIZ6QAbqVPDetDisErGpYsIu2kAG6l/OwMTh+Ur35gEWk3BXAbnF9SyNKNO9m1T8OSRaTtFMBtMGlEEU0Ob6xRN4SItJ0CuA3GDs4nNzONV3Q/sIi0gwK4DdJTY8OSX/mgCncPXY6IdFEK4DY6v6SQTTv2sWGbvi1ZRNpGAdxGk0qKAHQ3hIi0mQK4jU7sk83g3j3UDywibaYAbiMzY/KIvrxWXs3e/RpxJSKtpwBuh0+fPoB9BxpZuLIydCki0gUpgNth/JDe9M3L5E/LNidl/80DPWrqDuhuC5FuSE9Da4fUFOPy0QN4eNGH1NQdIC8rvd37dHdeKa/mP14s5+0NOwCY87f15GenM3ZQPqcV92r3MUSkc1AAt9P0sQN54PX1PPPuZr4y8YR27au2voEfPlnGH5d+RHF+D264qIQ7F5ZzwYgiyrfW8NcPqlj+0e4EVS4dQY/IlKNRALfT2MH5nNw/jz8s2tCuAK6sqWPGnMWs2rKb7108gr+fPIyMtBTuXFjO2MH5jBnUizVVtbywcisA727cyZjB+Qn6FJIszY/IbHbHwvKA1Uhnoz7gdjIzvjLxBN6r2E3Zpl1t2kfl7jqu/N0brK+u5f7rJjD74hIy0j7+T2NmDO+by1XjBwPwtXvf4t2NO9tbvogEpABOgOlji8nOSOXe19a2etsdtfv52n1vUVVTz39fP5ELRhQddf387AwAemWn840HFvOhRuKJdFkK4ATo1SOda845kWfe/YjVlXtavF1N3QFm3L+I9dv2cu+M8Zx1YkGLt33gugk0NDnXPbCIXXv1WEyRrkgBnCAzJ51EZlpqi/v4ausb+MYDi1nx0W7u+uqZnDOsT6uON7xvLndfcxYbt+9j5u9LqW9obEvZIhKQAjhB+uRmcv2koTzz7ke8/MHRnw9RW9/A1+9fxJIPd3LHVWcw5ZR+bTrmxJP68P+uOJ231m3n1nnvJf1eYXdn4/ZYl8d7Fbv4YGsNVTX1ukdZpI10F0QCzbpwOM+9t4Wbn1jGszeeR5/czE+sU1N3gG88sJglH+7kzqvO4NOnD2jXMaePLWZddS2/fqGcYX1z+O7k4e3a3+HU1jfwh7c+5JHFH7KmqhaAhe//7+i/7IxUIHYnR9+8rIQfX6S70hlwAmWlp/LLK8awY+9+vnrvW1Tvqf/Y8vcqdvHZ//hbdOY7tt3h22z2lBI+O2YgP//zKuaXJW5UnrvzxNubOP/nL/HT+SspyM7gJ9NPBeC6c4fw1YknMHVUP/r3jIXuRb94mXteWcuBxqaE1SDSnekMOMHGDM7n3mvH8425i7nwF3/l6gkn0Dcvk8Xrt/OXFVspzM3kD9dPZOJJrevzPRoz4+dfOp1NO/Zy06NLKcjOaHWf8qEqdu7j1nllvPxBFWedWMA9M8Zx5gmxi4T//NRyekaj/gpzMzllQE/uWFjO+CEF/HT+Sh4t3ci/fXE0Z53Yu92fTaQ7UwAnwXklhfzpxvP42XPvM+e1dTQ0OUV5mXzngmF85/xh9Mpu/5DlQ2Wlp3LvjPF8+b/e4FsPlvLAdeMZN6T1AdjU5Dy06ENun78SB3782VO55uwTSUmxY257/3UTWLhyK//81HKu+N0bfGvSSXzvkhFkpae24RNJshw6Og80Qi8UBXCSlPTLY87Xx9PQ2MSufQfonZOB2bFDrD1652Tw+29O5Cv3vMk19y3it189g4tObvkFvrVVe7h5XhmL1m3nvOGF/OwLoxncO7tVNUw5pR8ThvbmX+ev5L9eWcuL71fyyyvHcPqg/FZ+mpaprKnjjTXbWLm5BoBnl31EWkoKuZmx/9qVu+vo21P90vEOHZ0HGqEXigI4ydJSUw57MS5Z+vfK4tFvn8PX71/EN+eWcuOFw5l10XAy0458Frpr3wF+s7CcuW+sJys9lZ9/8XSuGDeozb8w8rLS+dkXTmfaqf25+YkyPv+frzNr8jBuuOiTI/zaYuP2vcxbUsELK7dSVhEbfZieGqt1594DNDQ5e6IzvAn/upBhRTl8ZsxAvnjmoFb/QhFJJgVwN1SUl8nj3/kUP/xjGXe+uJpnyzbznQuGcfnoAQfPDN2dtdW1PPVOBb9/cwM79x3gy+MG8/2pIxJ2J8PkkX1Z8L3z+fEzy7nzxdW8sLKSX1wxhlEDe7Z6X/UNjTy/YiuPLt7Ia6tj30Jy1gkF/GDaSC4YUcTI/nmU/PA5vnb2iQA0ufObF1dz6+Un89dVVdyxsJxfv1DOOSf14SsTT2Daqf0T8stApD0UwN1Uj4xUfnXlWD4zZiC3z3+ff3x8GbfMK+PEPtlkpaWydXcd22r3YwYXjezL96eO4NSBiX/UZa8e6fzqyrFcdtoAbplXxqd/8yrTxwzk+kknHfPRmu7Okg938OQ7FTy7bDM79x6gOL8Hs6eU8KWzBjGo4MhnsynR2fvM84cx8/xhVOzcx7y3N/Fo6UZufPgd+uRkcMW4wVw9YTAn9slJ6Gfeu7+BVVtqWLE59uS6l1dVcaCpidSoH33Oa+sYWpjD8L65FOf3aFH/unRPCuBu7sKRfZk8oohF67bz2upq1lTtoe5AE6OLezF6UC8uPLkvxfk9kl7HJaP6MX5IAXe9vIYHX9/AH5d+xIh+uVwwoohTB/aib89M0lNTqKk7wLrqvZSu386iddvZVrufrPQUpo7qzxfOLGZSSdHBIGuN4vwe3DilhFkXDufV1dU89OYG7nl1Lb97eQ2TSgq57LQBTDmlL/1a0V/s7mzdXc+KzbtYuTkWuCs/2s26bbXEj01ZsWU3aSlGY1Os8SfPrji4LDsjlVMH9uS04l6MLu7FacW9GFaU26bPKF1PlwlgM7sUuANIBe5199sDl9RlmBkTT+qT0Fvf2iI/O4NbLjuF704ezlNLK3iubAtzX9/A/sPcNzyooAcXjCzivOGFTD21/8Guk/ZKSTEuGFHEBSOK2LKrjkcXb+TxJRu59ckyeBJO7p/HqAE9OWVAT/r3yiI3K43s9FT27m9kd90BqmrqWVtdy9qqPazaUsOOuOdwDO7dg1P69+QzYwYyamBPRg3oyaSfv8TfXzDs4Dp3LCzn7X+6mLXVtayujO2jrGIXjyzayP0H1gPQIz2VUQN7Hgzk0cW9GFaUQ1pqy7tMmpqc3XUH2Fa7n2179rO9tp7qPfvZXrsfgOfKNtMY/ZZo/mvh/z6+jIKcDHrnpFOQnUFhbiZ9e2bSNy+LPjkZST1TP17vzOgSAWxmqcBvgUuATcBiM3va3VccfUvpjHr1SOfac4Zw7TlD2N/QxPpttVTX1NPkkJ2ZyqCCHh0yoq5/ryxmX1zC/5kynA+27uGFlVtZtG47f1tTzbx3Ko64XX52OkMLc5g6qj+jBsbC+uQBeQfvjT6WPrmZ9MnNZHzcbYKNTc6aqj2UbdpFWcUu3qvYxaOLN/LA6+sByEpPYXBBNn1yM+idk0FGasrBQN63v5Ha/Q3srW88GLo7avfT0HTkIeKVNfWkpRruHDxbf2lVJTv27udA4ye3S0sxCnMz6dczk6K8LPpFwVyYl0FORhrZGankZKaRlZ4CGGbQHNdmsbP/xianoakpeneaovfGJqemroFpo/rR5LH+e3d4cVUlc15bR2OTk5JipKcaqSlGekoKqSlGWqqRlpISvRtpqSmx97hlqSlGemrzu318PiWFlBRo8thfM83HbmqKm45qaYpbPqRPTsL+QukSAQxMAFa7+1oAM3sEmA4ogLu4jLQURvTLY0S/vGA1mBkj++cxsn8esy6Mte2o3U/1nnpq6hvYt7+RHhmp9MxKp09OBgU5GQmvITXFDv4cvnjWICAWymur9kSBvJuPdu5jW209q7bUsL+xiYYoKJvDLycjjcG9sxk7OD8K6kwKo8Duk5NJn9wMCrIzGPFPzzHjU0M+dvw7Fpaz6IcX4+7sqW9gR+0BqvbUU7m7jsqaerZG75U19WzasZclH+44eDadKAtWbP1EW3x3TWex9J8vOfhY2PayrvAgFTP7EnCpu18fzV8DTHT3G+LWmQnMjGZHAqtae5zUvMIzUnPyO92l8ca9u0jN7nzfBae6Wq4z1gSqq7Uaa3c2NdZUv9OGTavd/dJDG7vKGfAxufvdwN3t2YeZlTbsrhqXoJISxsxKG3ZVqq4W6ox1dcaaQHW1lpmVunvC6up0Z3tHUAEMjpsfFLWJiHRZXSWAFwMlZjbUzDKAq4CnA9ckItIuXaILwt0bzOwGYAGx29DmuPvyJByqXV0YSaS6Wqcz1tUZawLV1VoJratLXIQTEemOukoXhIhIt6MAFhEJRAFMbJizma0ys9VmdnPoepqZ2RwzqzSz90LX0szMBpvZS2a2wsyWm9ns0DUBmFmWmS0ys3ejun4cuqZ4ZpZqZu+Y2bOha2lmZuvNrMzMlppZaeh6mplZvpk9bmbvm9lKMzunE9Q0Mvo5Nb92m9lN7d7v8d4HHA1z/oC4Yc7A1Z1hmLOZnQ/sAR5099NC1wNgZgOAAe6+xMzygLeBz4X+eVns4cU57r7HzNKB14DZ7v5myLqamdn3gXFAT3f/u9D1QCyAgXHuXh26lnhmNhd41d3vje56ynb3nYHLOijKjApig8E2tGdfOgOOG+bs7vuB5mHOwbn7K8D20HXEc/fN7r4kmq4BVgLFYasCj9kTzaZHr05xdmFmg4BPA/eGrqWzM7NewPnAfQDuvr8zhW9kCrCmveELCmCIhcfGuPlNdIJA6QrMbAhwBvBW4FKAg3/mLwUqgefdvVPUBfwa+Eegs31dtAN/MbO3o6H8ncFQoAq4P+qyudfMEvvA5va7Cng4ETtSAEubmFku8ARwk7vvDl0PgLs3uvtYYiMlJ5hZ8G4bM/s7oNLd3w5dy2Gc5+5nApcBs6Iur9DSgDOBu9z9DKAW6EzXZTKAzwL/k4j9KYA1zLnVoj7WJ4CH3H1e6HoOFf3J+hLwiYefBHAu8Nmov/UR4CIz+++wJcW4e0X0Xgk8Saw7LrRNwKa4v14eJxbIncVlwBJ3/+Sj29pAAaxhzq0SXey6D1jp7r8KXU8zMysys/xougexi6rvBy0KcPdb3H2Quw8h9n/rRXf/WuCyMLOc6CIq0Z/4U4Hgd9u4+xZgo5mNjJqm0LkeO3s1Cep+gC4yFDmZOnCYc6uZ2cPAZKDQzDYBP3L3+8JWxbnANUBZ1N8KcKu7zw9XEgADgLnRFeoU4DF37zS3fHVC/YAno2++TgP+4O5/DlvSQTcCD0UnRGuB6wLXAxz8RXUJ8O2E7fN4vw1NRCQUdUGIiASiABYRCUQBLCISiAJYRCQQBbCISCAKYBGRQBTAIiKB/H+0Up1NwZq5nwAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 360x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "\"\"\" Filter Luhn Analysis \"\"\"\n",
    "\n",
    "def get_vocab(df, text_col='review_words'):\n",
    "    all_vocab = []\n",
    "    _ = [[all_vocab.append(w) for w in r.split()] for r in df[text_col].to_list() if type(r) is str]\n",
    "    vocab_occurrences = LIST.occurrences(all_vocab)\n",
    "    return vocab_occurrences\n",
    "\n",
    "# Distribution of log-corrected vocab occurrencies\n",
    "vocab = get_vocab(grc)\n",
    "vocab_log = DICT.apply_value(vocab, lambda f: round(UTILS.log(f), ndigits=1))\n",
    "vocab_log_distr = LIST.describe(vocab_log.values(), print_res=True, print_plot=True)\n",
    "\n",
    "# Keep from floor(skewness) to max-ceil(skewness)\n",
    "l_cutoff, u_cutoff = round(vocab_log_distr['skewness']), int(vocab_log_distr['max'])-math.ceil(vocab_log_distr['skewness'])\n",
    "keep_vocab = list(DICT.filter_value(vocab_log, lambda l: l_cutoff <= l and l <= u_cutoff).keys())\n",
    "\n",
    "# Filter luhn words\n",
    "grc['review_words_luhn'] = grc['review_words'].apply(lambda r: ' '.join([w for w in r.split() if w in keep_vocab]) if type(r) is str else ' ')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "<h3>Bigrams Constructs</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" POS dict \"\"\"\n",
    "pos_dict = UTILS.pkl_load('pkl/pos_dict.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" W2V Building \"\"\"\n",
    "\n",
    "# all_sentences = []\n",
    "# for r in trdf['review'].to_list():\n",
    "#   if type(r) is str: \n",
    "#       [all_sentences.append([w for w in s.split() if ((w in pos_dict and pos_dict[w][0] in ['N','J','V','R']) or UTILS.start_with(w,'not_'))]) for s in r.split('|')]\n",
    "\n",
    "# w2v_model_150 = ML.w2v(all_sentences, model='SG', vector_size=150, get_bigrams=True)\n",
    "# w2v_model_300 = ML.w2v(all_sentences, model='SG', vector_size=300, get_bigrams=True)\n",
    "# UTILS.pkl_save('pkl/w2v_150_NEGnot.pkl', w2v_model_150)\n",
    "# UTILS.pkl_save('pkl/w2v_300_NEGnot.pkl', w2v_model_300)\n",
    "\n",
    "# Loading Models\n",
    "w2v_model = UTILS.pkl_load('pkl/w2v_150_NEGnot.pkl')\n",
    "w2v_vocab = w2v_model.wv.key_to_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape: (102012, 16)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>drug</th>\n",
       "      <th>condition</th>\n",
       "      <th>original_review</th>\n",
       "      <th>review</th>\n",
       "      <th>review_words</th>\n",
       "      <th>rating</th>\n",
       "      <th>useful</th>\n",
       "      <th>date</th>\n",
       "      <th>order</th>\n",
       "      <th>review_words_luhn</th>\n",
       "      <th>all_bg</th>\n",
       "      <th>jn_constr</th>\n",
       "      <th>vj_constr</th>\n",
       "      <th>rj_constr</th>\n",
       "      <th>rv_constr</th>\n",
       "      <th>vr_constr</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2008-02-24</th>\n",
       "      <td>Chlorpheniramine / pseudoephedrine</td>\n",
       "      <td>Allergic Rhinitis</td>\n",
       "      <td>i when to a medical clinic with flu like sympt...</td>\n",
       "      <td>medical clinic flu symptom dr duty prescribe d...</td>\n",
       "      <td>medical clinic flu symptom dr duty prescribe d...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2008-02-24</td>\n",
       "      <td>0</td>\n",
       "      <td>medical clinic flu symptom dr duty know seriou...</td>\n",
       "      <td>symptom dr|flu symptom</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>symptom dr</td>\n",
       "      <td>flu symptom</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2008-02-24</th>\n",
       "      <td>Oxybutynin</td>\n",
       "      <td>Not Listed / Othe</td>\n",
       "      <td>improved my problem dramatically. i never expe...</td>\n",
       "      <td>improve problem dramatically|never experience ...</td>\n",
       "      <td>improve problem dramatically never experience ...</td>\n",
       "      <td>7.0</td>\n",
       "      <td>22</td>\n",
       "      <td>2008-02-24</td>\n",
       "      <td>1</td>\n",
       "      <td>improve dramatically major</td>\n",
       "      <td>experience major|never experience</td>\n",
       "      <td></td>\n",
       "      <td>experience major</td>\n",
       "      <td></td>\n",
       "      <td>never experience</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2008-02-24</th>\n",
       "      <td>Xenical</td>\n",
       "      <td>Obesity</td>\n",
       "      <td>xenical really helped me but some of the bowel...</td>\n",
       "      <td>xenical really help bowel problem make margina...</td>\n",
       "      <td>xenical really help bowel problem make margina...</td>\n",
       "      <td>7.0</td>\n",
       "      <td>50</td>\n",
       "      <td>2008-02-24</td>\n",
       "      <td>2</td>\n",
       "      <td>xenical bowel marginal hit</td>\n",
       "      <td>hit side</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>hit side</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2008-02-24</th>\n",
       "      <td>Macrobid</td>\n",
       "      <td>Bladder Infection</td>\n",
       "      <td>excellent for prevention of bladder infection ...</td>\n",
       "      <td>excellent prevention bladder infection cns com...</td>\n",
       "      <td>excellent prevention bladder infection cns com...</td>\n",
       "      <td>8.0</td>\n",
       "      <td>52</td>\n",
       "      <td>2008-02-24</td>\n",
       "      <td>3</td>\n",
       "      <td>excellent prevention bladder infection cns com...</td>\n",
       "      <td>bladder infection</td>\n",
       "      <td></td>\n",
       "      <td>bladder infection</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2008-02-25</th>\n",
       "      <td>Fentanyl</td>\n",
       "      <td>Pain</td>\n",
       "      <td>i don t think i could make it without the patc...</td>\n",
       "      <td>not_think make patch|pain back point live|fent...</td>\n",
       "      <td>not_think make patch pain back point live fent...</td>\n",
       "      <td>10.0</td>\n",
       "      <td>22</td>\n",
       "      <td>2008-02-25</td>\n",
       "      <td>4</td>\n",
       "      <td>not_think patch point live patch way</td>\n",
       "      <td>make patch|much pain|not_think make|take much|...</td>\n",
       "      <td>make patch|much pain</td>\n",
       "      <td>not_think make|take much</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>point live</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          drug          condition  \\\n",
       "date                                                                \n",
       "2008-02-24  Chlorpheniramine / pseudoephedrine  Allergic Rhinitis   \n",
       "2008-02-24                          Oxybutynin  Not Listed / Othe   \n",
       "2008-02-24                             Xenical            Obesity   \n",
       "2008-02-24                            Macrobid  Bladder Infection   \n",
       "2008-02-25                            Fentanyl               Pain   \n",
       "\n",
       "                                              original_review  \\\n",
       "date                                                            \n",
       "2008-02-24  i when to a medical clinic with flu like sympt...   \n",
       "2008-02-24  improved my problem dramatically. i never expe...   \n",
       "2008-02-24  xenical really helped me but some of the bowel...   \n",
       "2008-02-24  excellent for prevention of bladder infection ...   \n",
       "2008-02-25  i don t think i could make it without the patc...   \n",
       "\n",
       "                                                       review  \\\n",
       "date                                                            \n",
       "2008-02-24  medical clinic flu symptom dr duty prescribe d...   \n",
       "2008-02-24  improve problem dramatically|never experience ...   \n",
       "2008-02-24  xenical really help bowel problem make margina...   \n",
       "2008-02-24  excellent prevention bladder infection cns com...   \n",
       "2008-02-25  not_think make patch|pain back point live|fent...   \n",
       "\n",
       "                                                 review_words  rating  useful  \\\n",
       "date                                                                            \n",
       "2008-02-24  medical clinic flu symptom dr duty prescribe d...     1.0       0   \n",
       "2008-02-24  improve problem dramatically never experience ...     7.0      22   \n",
       "2008-02-24  xenical really help bowel problem make margina...     7.0      50   \n",
       "2008-02-24  excellent prevention bladder infection cns com...     8.0      52   \n",
       "2008-02-25  not_think make patch pain back point live fent...    10.0      22   \n",
       "\n",
       "                  date  order  \\\n",
       "date                            \n",
       "2008-02-24  2008-02-24      0   \n",
       "2008-02-24  2008-02-24      1   \n",
       "2008-02-24  2008-02-24      2   \n",
       "2008-02-24  2008-02-24      3   \n",
       "2008-02-25  2008-02-25      4   \n",
       "\n",
       "                                            review_words_luhn  \\\n",
       "date                                                            \n",
       "2008-02-24  medical clinic flu symptom dr duty know seriou...   \n",
       "2008-02-24                         improve dramatically major   \n",
       "2008-02-24                         xenical bowel marginal hit   \n",
       "2008-02-24  excellent prevention bladder infection cns com...   \n",
       "2008-02-25               not_think patch point live patch way   \n",
       "\n",
       "                                                       all_bg  \\\n",
       "date                                                            \n",
       "2008-02-24                             symptom dr|flu symptom   \n",
       "2008-02-24                  experience major|never experience   \n",
       "2008-02-24                                           hit side   \n",
       "2008-02-24                                  bladder infection   \n",
       "2008-02-25  make patch|much pain|not_think make|take much|...   \n",
       "\n",
       "                       jn_constr                 vj_constr rj_constr  \\\n",
       "date                                                                   \n",
       "2008-02-24                                                             \n",
       "2008-02-24                                experience major             \n",
       "2008-02-24                                                             \n",
       "2008-02-24                               bladder infection             \n",
       "2008-02-25  make patch|much pain  not_think make|take much             \n",
       "\n",
       "                   rv_constr    vr_constr  \n",
       "date                                       \n",
       "2008-02-24        symptom dr  flu symptom  \n",
       "2008-02-24  never experience               \n",
       "2008-02-24                       hit side  \n",
       "2008-02-24                                 \n",
       "2008-02-25                     point live  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\" Cerca costrutti grammaticali \"\"\"\n",
    "\n",
    "jn_constr = ('J', 'N')      # aggettivo  +  nome            # conoscienza comune\n",
    "vj_constr = ('V', 'J')      # verbo      +  aggettivo       # https://www.grammarly.com/blog/adjective-and-verb-placement/#:~:text=Adjectives%20are%20usually%20placed%20before,are%20placed%20after%20the%20verb.&text=%E2%80%9CSense%E2%80%9D%20verbs%2C%20such%20as,The%20cookies%20smell%20awesome%20!\n",
    "rj_constr = ('R', 'J')      # avverbio   +  aggettivo       # https://site.uit.no/english/grammar/adverb-placement/#:~:text=Adverbs%20can%20be%20used%20to,%2C%20recently%20re%2Delected%20president.\n",
    "rv_constr = ('R', 'V')      # avverbio   +  verbo           # https://site.uit.no/english/grammar/adverb-placement/#:~:text=Adverbs%20can%20be%20used%20to,%2C%20recently%20re%2Delected%20president.\n",
    "vr_constr = ('V', 'R')      # verbo      +  avverbio        # https://site.uit.no/english/grammar/adverb-placement/#:~:text=Adverbs%20can%20be%20used%20to,%2C%20recently%20re%2Delected%20president.\n",
    "grammar_constrs = [jn_constr, vj_constr, rj_constr, rv_constr, vr_constr]\n",
    "\n",
    "# Considerare parole che esistono anche in w2v_vocab\n",
    "do_check_vocab = True \n",
    "check_vocab = w2v_vocab #list(set(affspace['concept'].to_list()))\n",
    "def get_biConstrcut(sentence, construct):\n",
    "    constructs = []\n",
    "    if type(sentence) is str:\n",
    "        words = sentence.split()\n",
    "\n",
    "        _ = [constructs.append([w, words[i+1]]) for i,w in enumerate(words[:-1]) if (((w in check_vocab and words[i+1] in check_vocab) or (UTILS.start_with(w,'not_')  and UTILS.start_with(words[i+1],'not')) if do_check_vocab else True) and\n",
    "                                                                                    ((w in pos_dict and pos_dict[w][0]==construct[0] and words[i+1] in pos_dict and pos_dict[words[i+1]][0]==construct[1]) or \n",
    "                                                                                    ((w in pos_dict and pos_dict[w][0]==construct[0] and (UTILS.start_with(words[i+1],'not_') and words[i+1][len('not_'):] in pos_dict and pos_dict[words[i+1][len('not_'):]][0]==construct[1])) or \n",
    "                                                                                     ((UTILS.start_with(w,'not_') and w[len('not_'):] in pos_dict and pos_dict[w[len('not_'):]][0]==construct[0]) and words[i+1] in pos_dict and pos_dict[words[i+1]][0]==construct[1] ))))]\n",
    "    return constructs\n",
    "\n",
    "def sentences_biContruct(sentences, construct, to_str=False):\n",
    "    constr_list = []\n",
    "    if type(sentences) is str:\n",
    "        _ = [[constr_list.append(c) for c in sc] for sc in LIST.lfilter([get_biConstrcut(s, construct) for s in sentences.split('|')], lambda v: len(v)>0)]\n",
    "    if to_str:\n",
    "        return '|'.join([' '.join(w) for w in constr_list])\n",
    "    else:\n",
    "        return constr_list\n",
    "\n",
    "grc['all_bg'] = ''\n",
    "for grammar_constr in grammar_constrs:\n",
    "    column_name = grammar_constr[0].lower()+grammar_constr[1].lower()+'_'+'constr'\n",
    "    grc[column_name] = grc['review'].apply(lambda review: sentences_biContruct(review, grammar_constr, to_str=True))\n",
    "    grc['all_bg'] = grc.apply(lambda r:r['all_bg'] + ('|' if r[column_name]!='' and r['all_bg']!='' else '') + r[column_name], axis=1)\n",
    "# grc['all_bg'] = grc['all_bg'].apply(lambda bgl: UTILS.str_replace(bgl, {' ':'_','|':' '}))\n",
    "\n",
    "# DF.wcsv(grc, 'grc/'+target_condition+'.csv', sep='\\t')\n",
    "\n",
    "print('shape:', grc.shape)\n",
    "grc.head(5)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "3cf66169115c652bb79acb2588442f4af23d45749f4b7392481eb4fdb63a6d4b"
  },
  "kernelspec": {
   "display_name": "Python 3.9.1 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
